{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNT4RCRrWNV5Ii4/1W1dXM2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HamzaWajid1/Zabaan_v1/blob/main/ZABAN_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xvIX1D1Y7D37",
        "outputId": "b3f7aa7b-759c-455a-e99f-61fb6d0f48f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting ibm_watson\n",
            "  Downloading ibm-watson-7.0.1.tar.gz (389 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.3/389.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from ibm_watson) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from ibm_watson) (2.8.2)\n",
            "Requirement already satisfied: websocket-client>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from ibm_watson) (1.7.0)\n",
            "Collecting ibm-cloud-sdk-core==3.*,>=3.3.6 (from ibm_watson)\n",
            "  Downloading ibm-cloud-sdk-core-3.19.1.tar.gz (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urllib3<3.0.0,>=2.1.0 (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson)\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyJWT<3.0.0,>=2.8.0 (from ibm-cloud-sdk-core==3.*,>=3.3.6->ibm_watson)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.5.3->ibm_watson) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->ibm_watson) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->ibm_watson) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2023.11.17)\n",
            "Building wheels for collected packages: ibm_watson, ibm-cloud-sdk-core\n",
            "  Building wheel for ibm_watson (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm_watson: filename=ibm_watson-7.0.1-py3-none-any.whl size=389784 sha256=12be7b9bef6042d16341f1a147e83f9837ba03da8d5379ddf57190e683b67132\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/df/f4/f8edc5ba0637dd4bfb2029741ae20402976a49d1b6bc113553\n",
            "  Building wheel for ibm-cloud-sdk-core (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.19.1-py3-none-any.whl size=95828 sha256=f95adececec8cf12c99df249b71a95f0e6d0709d1282a64dcacf8a3e3f20d1e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/b9/b2/2316e6df1fb93353a388ef07032b10655ca871c173b241e788\n",
            "Successfully built ibm_watson ibm-cloud-sdk-core\n",
            "Installing collected packages: urllib3, PyJWT, ibm-cloud-sdk-core, ibm_watson\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: PyJWT\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed PyJWT-2.8.0 ibm-cloud-sdk-core-3.19.1 ibm_watson-7.0.1 urllib3-2.1.0\n",
            "Collecting timestamps\n",
            "  Downloading timestamps-1.3.0-py3-none-any.whl (3.1 kB)\n",
            "Installing collected packages: timestamps\n",
            "Successfully installed timestamps-1.3.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Collecting uuid\n",
            "  Downloading uuid-1.30.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Building wheels for collected packages: uuid\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uuid: filename=uuid-1.30-py3-none-any.whl size=6479 sha256=adf7baa8c86c45a7fbdf1e2d857408ca46d30daa6da6a9d8e15bf453aa7ec7e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/08/9e/f0a977dfe55051a07e21af89200125d65f1efa60cbac61ed88\n",
            "Successfully built uuid\n",
            "Installing collected packages: uuid\n",
            "Successfully installed uuid-1.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "uuid"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vits'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 81 (delta 21), reused 21 (delta 21), pack-reused 26\u001b[K\n",
            "Receiving objects: 100% (81/81), 3.33 MiB | 6.94 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "Python 3.10.12\n",
            "/content/vits\n",
            "Collecting Cython==0.29.21\n",
            "  Downloading Cython-0.29.21-py2.py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.2/974.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 3.0.8\n",
            "    Uninstalling Cython-3.0.8:\n",
            "      Successfully uninstalled Cython-3.0.8\n",
            "Successfully installed Cython-0.29.21\n",
            "Collecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (3.0.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.3.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.8.0)\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa==0.8.0) (1.8.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.43.0->librosa==0.8.0) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa==0.8.0) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.9.0->librosa==0.8.0) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.8.0) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0) (2023.11.17)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201368 sha256=b3e419ac29fd657c7316431682fe0ab783e1007f40d499dc8c415aac72ca15bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/b7/85/2f8044306ccec014930aea23ad4852fca9e2584e21c6972bc6\n",
            "Successfully built librosa\n",
            "Installing collected packages: resampy, librosa\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.1\n",
            "    Uninstalling librosa-0.10.1:\n",
            "      Successfully uninstalled librosa-0.10.1\n",
            "Successfully installed librosa-0.8.0 resampy-0.4.2\n",
            "Collecting phonemizer==2.2.1\n",
            "  Downloading phonemizer-2.2.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.0/49.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from phonemizer==2.2.1) (1.3.2)\n",
            "Collecting segments (from phonemizer==2.2.1)\n",
            "  Downloading segments-2.2.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs>=18.1 in /usr/local/lib/python3.10/dist-packages (from phonemizer==2.2.1) (23.2.0)\n",
            "Collecting clldutils>=1.7.3 (from segments->phonemizer==2.2.1)\n",
            "  Downloading clldutils-3.22.1-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting csvw>=1.5.6 (from segments->phonemizer==2.2.1)\n",
            "  Downloading csvw-3.3.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from segments->phonemizer==2.2.1) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer==2.2.1) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer==2.2.1) (0.9.0)\n",
            "Collecting colorlog (from clldutils>=1.7.3->segments->phonemizer==2.2.1)\n",
            "  Downloading colorlog-6.8.0-py3-none-any.whl (11 kB)\n",
            "Collecting bibtexparser>=2.0.0b4 (from clldutils>=1.7.3->segments->phonemizer==2.2.1)\n",
            "  Downloading bibtexparser-2.0.0b6-py3-none-any.whl (38 kB)\n",
            "Collecting pylatexenc (from clldutils>=1.7.3->segments->phonemizer==2.2.1)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer==2.2.1) (3.5.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer==2.2.1) (4.9.4)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from clldutils>=1.7.3->segments->phonemizer==2.2.1) (2.1.4)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer==2.2.1) (2.14.0)\n",
            "Collecting colorama (from csvw>=1.5.6->segments->phonemizer==2.2.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting isodate (from csvw>=1.5.6->segments->phonemizer==2.2.1)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer==2.2.1) (4.19.2)\n",
            "Collecting language-tags (from csvw>=1.5.6->segments->phonemizer==2.2.1)\n",
            "  Downloading language_tags-1.2.0-py3-none-any.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdflib (from csvw>=1.5.6->segments->phonemizer==2.2.1)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer==2.2.1) (2.31.0)\n",
            "Collecting rfc3986<2 (from csvw>=1.5.6->segments->phonemizer==2.2.1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: uritemplate>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from csvw>=1.5.6->segments->phonemizer==2.2.1) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate->csvw>=1.5.6->segments->phonemizer==2.2.1) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer==2.2.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer==2.2.1) (0.32.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->csvw>=1.5.6->segments->phonemizer==2.2.1) (0.17.1)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->csvw>=1.5.6->segments->phonemizer==2.2.1) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer==2.2.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer==2.2.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer==2.2.1) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->csvw>=1.5.6->segments->phonemizer==2.2.1) (2023.11.17)\n",
            "Building wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136816 sha256=9e33754f59d004b93277ad68ab4af4ff09e352e9454243cab82b2b2e70a37b60\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/31/8b/e09b0386afd80cfc556c00408c9aeea5c35c4d484a9c762fd5\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: rfc3986, pylatexenc, language-tags, isodate, colorlog, colorama, bibtexparser, rdflib, clldutils, csvw, segments, phonemizer\n",
            "Successfully installed bibtexparser-2.0.0b6 clldutils-3.22.1 colorama-0.4.6 colorlog-6.8.0 csvw-3.3.0 isodate-0.6.1 language-tags-1.2.0 phonemizer-2.2.1 pylatexenc-2.10 rdflib-7.0.0 rfc3986-1.5.0 segments-2.2.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting Unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.3/238.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Unidecode\n",
            "Successfully installed Unidecode-1.1.1\n",
            "/content/vits/monotonic_align\n",
            "Compiling core.pyx because it changed.\n",
            "[1/1] Cythonizing core.pyx\n",
            "/usr/local/lib/python3.10/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/vits/monotonic_align/core.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "\u001b[01m\u001b[Kcore.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[K__Pyx_InitGlobals\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kcore.c:16766:1:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[KPyEval_InitThreads\u001b[m\u001b[K’ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "16766 | \u001b[01;35m\u001b[KPyEval_InitThreads\u001b[m\u001b[K();\n",
            "      | \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/include/python3.10/Python.h:130\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcore.c:16\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/python3.10/ceval.h:122:37:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
            "  122 | Py_DEPRECATED(3.9) PyAPI_FUNC(void) \u001b[01;36m\u001b[KPyEval_InitThreads\u001b[m\u001b[K(void);\n",
            "      |                                     \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "/content/vits\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire) (2.4.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=216517868907470ca5c5a75e807700b0109167e600669fc747ed524bb8539f24\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.5.0\n",
            "Collecting commons\n",
            "  Downloading commons-0.7.tar.gz (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "%pip install pytube\n",
        "%pip install ibm_watson\n",
        "%pip install timestamps\n",
        "%pip install requests uuid\n",
        "#@title Automatic Setup\n",
        "%pwd\n",
        "!git clone https://github.com/jaywalnut310/vits.git\n",
        "!python --version\n",
        "%cd vits/\n",
        "\n",
        "!pip install Cython==0.29.21\n",
        "!pip install librosa==0.8.0\n",
        "!pip install phonemizer==2.2.1\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install Unidecode==1.1.1\n",
        "\n",
        "%cd monotonic_align/\n",
        "%mkdir monotonic_align\n",
        "!python3 setup.py build_ext --inplace\n",
        "%cd ../\n",
        "%pwd\n",
        "%pip install fire\n",
        "%pip install commons\n",
        "%pip install pydub\n",
        "%pip install moviepy pydub imageio[ffmpeg]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from ibm_watson import SpeechToTextV1\n",
        "from ibm_watson.websocket import RecognizeCallback, AudioSource\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip, concatenate_videoclips\n",
        "import os\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import soundfile as sf\n",
        "import shutil\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "from IPython.display import Audio\n",
        "import re\n",
        "import glob\n",
        "import json\n",
        "import tempfile\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import commons\n",
        "import utils\n",
        "import argparse\n",
        "from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
        "from models import SynthesizerTrn\n",
        "from scipy.io.wavfile import write\n",
        "import requests, uuid, json\n",
        "from pytube import YouTube\n",
        "import pandas as pd\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "import io\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6zZBz95b7tU8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Meta code\n",
        "\n",
        "#Downloading language model\n",
        "def download(lang, tgt_dir=\"./\"):\n",
        "  lang_fn, lang_dir = os.path.join(tgt_dir, lang+'.tar.gz'), os.path.join(tgt_dir, lang)\n",
        "  cmd = \";\".join([\n",
        "        f\"wget https://dl.fbaipublicfiles.com/mms/tts/{lang}.tar.gz -O {lang_fn}\",\n",
        "        f\"tar zxvf {lang_fn}\"\n",
        "  ])\n",
        "  print(f\"Download model for language: {lang}\")\n",
        "  subprocess.check_output(cmd, shell=True)\n",
        "  print(f\"Model checkpoints in {lang_dir}: {os.listdir(lang_dir)}\")\n",
        "  return lang_dir\n",
        "\n",
        "#deals with special characters in specific language\n",
        "def preprocess_char(text, lang=None):\n",
        "    \"\"\"\n",
        "    Special treatement of characters in certain languages\n",
        "    \"\"\"\n",
        "    print(lang)\n",
        "    if lang == 'ron':\n",
        "        text = text.replace(\"ț\", \"ţ\")\n",
        "    return text\n",
        "\n",
        "#Class for reading text to generate voice\n",
        "class TextMapper(object):\n",
        "    def __init__(self, vocab_file):\n",
        "        self.symbols = [x.replace(\"\\n\", \"\") for x in open(vocab_file, encoding=\"utf-8\").readlines()]\n",
        "        self.SPACE_ID = self.symbols.index(\" \")\n",
        "        self._symbol_to_id = {s: i for i, s in enumerate(self.symbols)}\n",
        "        self._id_to_symbol = {i: s for i, s in enumerate(self.symbols)}\n",
        "\n",
        "    def text_to_sequence(self, text, cleaner_names):\n",
        "        '''Converts a string of text to a sequence of IDs corresponding to the symbols in the text.\n",
        "        Args:\n",
        "        text: string to convert to a sequence\n",
        "        cleaner_names: names of the cleaner functions to run the text through\n",
        "        Returns:\n",
        "        List of integers corresponding to the symbols in the text\n",
        "        '''\n",
        "        sequence = []\n",
        "        clean_text = text.strip()\n",
        "        for symbol in clean_text:\n",
        "            symbol_id = self._symbol_to_id[symbol]\n",
        "            sequence += [symbol_id]\n",
        "        return sequence\n",
        "    #some words in punjabi cannot be translated in english , those words are replaced with roman english\n",
        "    def uromanize(self, text, uroman_pl):\n",
        "        iso = \"xxx\"\n",
        "        with tempfile.NamedTemporaryFile() as tf, \\\n",
        "             tempfile.NamedTemporaryFile() as tf2:\n",
        "            with open(tf.name, \"w\") as f:\n",
        "                f.write(\"\\n\".join([text]))\n",
        "            cmd = f\"perl \" + uroman_pl\n",
        "            cmd += f\" -l {iso} \"\n",
        "            cmd +=  f\" < {tf.name} > {tf2.name}\"\n",
        "            os.system(cmd)\n",
        "            outtexts = []\n",
        "            with open(tf2.name) as f:\n",
        "                for line in f:\n",
        "                    line =  re.sub(r\"\\s+\", \" \", line).strip()\n",
        "                    outtexts.append(line)\n",
        "            outtext = outtexts[0]\n",
        "        return outtext\n",
        "    #reading the punjabi text and also normalizing it.\n",
        "    def get_text(self, text, hps):\n",
        "        text_norm = self.text_to_sequence(text, hps.data.text_cleaners)\n",
        "        if hps.data.add_blank:\n",
        "            text_norm = commons.intersperse(text_norm, 0)\n",
        "        text_norm = torch.LongTensor(text_norm)\n",
        "        return text_norm\n",
        "\n",
        "    def filter_oov(self, text):\n",
        "        val_chars = self._symbol_to_id\n",
        "        txt_filt = \"\".join(list(filter(lambda x: x in val_chars, text)))\n",
        "        return txt_filt\n",
        "\n",
        "#It is basically categorizing text into roman or punjabi and also lowering the cases\n",
        "def preprocess_text(txt, text_mapper, hps, uroman_dir=None, lang=None):\n",
        "    txt = preprocess_char(txt, lang=lang)\n",
        "    is_uroman = hps.data.training_files.split('.')[-1] == 'uroman'\n",
        "    if is_uroman:\n",
        "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
        "            if uroman_dir is None:\n",
        "                cmd = f\"git clone git@github.com:isi-nlp/uroman.git {tmp_dir}\"\n",
        "                print(cmd)\n",
        "                subprocess.check_output(cmd, shell=True)\n",
        "                uroman_dir = tmp_dir\n",
        "            uroman_pl = os.path.join(uroman_dir, \"bin\", \"uroman.pl\")\n",
        "            print(f\"uromanize\")\n",
        "            txt = text_mapper.uromanize(txt, uroman_pl)\n",
        "            print(f\"uroman text: {txt}\")\n",
        "    txt = txt.lower()\n",
        "    txt = text_mapper.filter_oov(txt)\n",
        "    return txt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#IBM api key for speech to text in english.It is free\n",
        "apikey = 'h3bMgb4Tldj2cqh9PDA2KieD1kprny4CpQBXp_TttbpB'\n",
        "url = 'https://api.au-syd.speech-to-text.watson.cloud.ibm.com/instances/43b3559e-bba6-427b-b4c2-3a5f6a601855'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Azure Api for translation.It is paid\n",
        "key = \"ded01807d1b340f9ac302e611498c392\"\n",
        "endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
        "\n",
        "# location, also known as region.\n",
        "# required if you're using a multi-service or regional (not global) resource. It can be found in the Azure portal on the Keys and Endpoint page.\n",
        "location = \"southeastasia\"\n",
        "\n",
        "path = '/translate'\n",
        "constructed_url = endpoint + path\n",
        "\n",
        "params = {\n",
        "    'api-version': '3.0',\n",
        "    'from': 'en',\n",
        "    'to': ['pa']\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    'Ocp-Apim-Subscription-Key': key,\n",
        "     # location required if you're using a multi-service or regional (not global) resource.\n",
        "    'Ocp-Apim-Subscription-Region': location,\n",
        "    'Content-type': 'application/json',\n",
        "    'X-ClientTraceId': str(uuid.uuid4())\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#Acual list is storing the actual text, start list will store start time of text while end_list will store end time of text\n",
        "actual_list = []\n",
        "start_list=[]\n",
        "end_list=[]\n",
        "\n",
        "\n",
        "\n",
        "#Storing of punjabi text\n",
        "Punjabi_list = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Storing generated chunks of audios as AudioSegment\n",
        "generated_audios = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# List to store the stretched audio segments\n",
        "stretched_segments = []\n",
        "\n",
        "\n",
        "\n",
        "# Function to speed up audio\n",
        "def speed_up_audio(audio, speed_factor):\n",
        "    # Speed up the audio\n",
        "    sped_up_audio = audio.speedup(playback_speed=speed_factor)\n",
        "    return sped_up_audio\n",
        "\n",
        "# Function to create an empty audio segment\n",
        "def create_empty_segment(duration):\n",
        "    return AudioSegment.silent(duration=duration * 1000)  # Duration in milliseconds\n",
        "\n",
        "# Function to add an audio segment to the project at a specific time\n",
        "def add_audio_at_time(project, audio_segment, start_time, end_time):\n",
        "    project = project[:start_time * 1000] + audio_segment + project[end_time * 1000:]\n",
        "    return project"
      ],
      "metadata": {
        "id": "fMKLWATi86Ff"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LANG = \"pan\"\n",
        "\n",
        "ckpt_dir = download(LANG)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Run inference with {device}\")\n",
        "vocab_file = f\"{ckpt_dir}/vocab.txt\"\n",
        "config_file = f\"{ckpt_dir}/config.json\"\n",
        "assert os.path.isfile(config_file), f\"{config_file} doesn't exist\"\n",
        "hps = utils.get_hparams_from_file(config_file)\n",
        "text_mapper = TextMapper(vocab_file)\n",
        "net_g = SynthesizerTrn(\n",
        "    len(text_mapper.symbols),\n",
        "    hps.data.filter_length // 2 + 1,\n",
        "    hps.train.segment_size // hps.data.hop_length,\n",
        "    **hps.model)\n",
        "net_g.to(device)\n",
        "_ = net_g.eval()\n",
        "\n",
        "g_pth = f\"{ckpt_dir}/G_100000.pth\"\n",
        "print(f\"load {g_pth}\")\n",
        "\n",
        "_ = utils.load_checkpoint(g_pth, net_g, None)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# link of the video to be downloaded\n",
        "link=\"https://www.youtube.com/watch?v=A98wPKiPMJw\"\n",
        "yt = YouTube(link)\n",
        "\n",
        "try:\n",
        "    yt.streams.filter(progressive = True,\n",
        "file_extension = \"mp4\").first().download(output_path = \"/content/\",\n",
        "filename = \"a.mp4\")\n",
        "except:\n",
        "    print(\"Some Error!\")\n",
        "print('Task Completed!')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Talha will need to change its path(mp4 converted to audio)\n",
        "command = 'ffmpeg -i /content/a.mp4 -ab 160k -ar 44100 -vn /content/audio.wav'\n",
        "subprocess.call(command, shell=True)\n",
        "\n",
        "\n",
        "\n",
        "#Speech to text\n",
        "authenticator = IAMAuthenticator(apikey)\n",
        "stt = SpeechToTextV1(authenticator=authenticator)\n",
        "stt.set_service_url(url)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Talha will need to change path\n",
        "#Extracting text from audio with time stamps using IBM service\n",
        "with open('/content/audio.wav', 'rb') as f:\n",
        "    res = stt.recognize(audio=f, content_type='audio/wav', model='en-AU_NarrowbandModel', timestamps=True).get_result()\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,len(res['results'])):\n",
        "  actual_list.append(res['results'][i]['alternatives'][0]['transcript'])\n",
        "  start_list.append(res['results'][i]['alternatives'][0]['timestamps'][0][1])\n",
        "  end_list.append(res['results'][i]['alternatives'][0]['timestamps'][-1][2])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a list of lists\n",
        "data = list(zip(actual_list, start_list, end_list))\n",
        "# Create a DataFrame from the list of lists\n",
        "df = pd.DataFrame(data, columns=['Text', 'start_time', 'end_time'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Azure translation service being used here to translate all the chunks of text\n",
        "for i in range(len(df)):\n",
        "  text=str(df['Text'][i])\n",
        "  # You can pass more than one object in body.\n",
        "  body = [{\n",
        "      'text': text\n",
        "  }]\n",
        "  request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
        "  response = request.json()\n",
        "  #print(json.dumps(response, sort_keys=True, ensure_ascii=False, indent=4, separators=(',', ': ')))\n",
        "  translated_text=response[0]['translations'][0]['text']\n",
        "  Punjabi_list.append(translated_text)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df[\"translated\"]=Punjabi_list\n",
        "df['duration']=df['end_time']-df['start_time']\n",
        "df['duration']=df['duration'].astype(float)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(Punjabi_list)):\n",
        "    txt = str(df['translated'][i])\n",
        "    txt = preprocess_text(txt, text_mapper, hps, lang=LANG)\n",
        "    stn_tst = text_mapper.get_text(txt, hps)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x_tst = stn_tst.unsqueeze(0).to(device)\n",
        "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
        "        hyp = net_g.infer(\n",
        "            x_tst, x_tst_lengths, noise_scale=.667,\n",
        "            noise_scale_w=0.8, length_scale=1.0\n",
        "        )[0][0,0].cpu().float().numpy()\n",
        "\n",
        "    print(f\"Generated audio\")\n",
        "\n",
        "    # Convert the generated audio array to 16-bit PCM format\n",
        "    hyp_int16 = (hyp * 32767).astype(np.int16)\n",
        "\n",
        "    # Create an AudioSegment from the NumPy array\n",
        "    hyp1 = AudioSegment(\n",
        "        hyp_int16.tobytes(),\n",
        "        frame_rate=hps.data.sampling_rate,\n",
        "        sample_width=hyp_int16.dtype.itemsize,\n",
        "        channels=1\n",
        "    )\n",
        "    # Append the file path to the list\n",
        "    generated_audios.append(hyp1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Talha will need to change path and delete original audio for optimization\n",
        "original=AudioSegment.from_wav(\"/content/audio.wav\")\n",
        "os.remove(\"/content/audio.wav\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Specify the duration of the empty audio (in seconds)\n",
        "empty_duration = len(original) / 1000\n",
        "# Create an empty audio segment\n",
        "project = create_empty_segment(empty_duration)\n",
        "\n",
        "\n",
        "# Assuming stretched is a list of AudioSegment objects\n",
        "for i in range(len(df)):\n",
        "    # Example usage: Replace this line with your code to get the stretched audio segment\n",
        "    stretched_audio = generated_audios[i]\n",
        "\n",
        "    # Speed up the audio segment based on the duration\n",
        "    speed_factor = (len(stretched_audio)/1000) / df['duration'].iloc[i]\n",
        "    stretched_audio = speed_up_audio(stretched_audio, speed_factor)\n",
        "\n",
        "    # Append the stretched audio segment to the list\n",
        "    stretched_segments.append(stretched_audio)\n",
        "\n",
        "# Add each stretched audio segment to the project at the specified start and end times\n",
        "for i, stretched_audio in enumerate(stretched_segments):\n",
        "    project = add_audio_at_time(project, stretched_audio, df['start_time'].iloc[i], df['end_time'].iloc[i])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "audio_segment = project\n",
        "\n",
        "# Convert AudioSegment to MP3 format\n",
        "mp3_data = audio_segment.export(format=\"mp3\").read()\n",
        "\n",
        "# Save the MP3 data to a temporary file\n",
        "temp_mp3_path = \"/content/temp_audio.mp3\"\n",
        "with open(temp_mp3_path, \"wb\") as f:\n",
        "    f.write(mp3_data)\n",
        "\n",
        "# Open the video and audio\n",
        "video_clip = VideoFileClip(\"/content/a.mp4\")\n",
        "os.remove(\"/content/a.mp4\")\n",
        "audio_clip = AudioFileClip(temp_mp3_path)\n",
        "\n",
        "# Set the audio of the video clip to the loaded audio\n",
        "video_clip = video_clip.set_audio(audio_clip)\n",
        "\n",
        "# Write the new video with the added audio to a file or display it\n",
        "video_clip.write_videofile('/content/output_video.mp4', codec='libx264', audio_codec='aac')\n",
        "\n",
        "# Cleanup: Delete the temporary MP3 file\n",
        "os.remove(temp_mp3_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Acual list is storing the actual text, start list will store start time of text while end_list will store end time of text\n",
        "actual_list = []\n",
        "start_list=[]\n",
        "end_list=[]\n",
        "#Storing of punjabi text\n",
        "Punjabi_list = []\n",
        "#Storing generated chunks of audios as AudioSegment\n",
        "generated_audios = []\n",
        "# List to store the stretched audio segments\n",
        "stretched_segments = []\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHxjlk0S9WP0",
        "outputId": "12f9cdf7-2333-4450-ca71-8cd852127181"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download model for language: pan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[WARNING] /usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoints in ./pan: ['config.json', 'vocab.txt', 'G_100000.pth']\n",
            "Run inference with cuda\n",
            "load ./pan/G_100000.pth\n",
            "Task Completed!\n",
            "pan\n",
            "Generated audio\n",
            "pan\n",
            "Generated audio\n",
            "pan\n",
            "Generated audio\n",
            "pan\n",
            "Generated audio\n",
            "pan\n",
            "Generated audio\n",
            "pan\n",
            "Generated audio\n",
            "Moviepy - Building video /content/output_video.mp4.\n",
            "MoviePy - Writing audio in output_videoTEMP_MPY_wvf_snd.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "Moviepy - Writing video /content/output_video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t: 100%|█████████▉| 7166/7190 [00:34<00:00, 249.19it/s, now=None][WARNING] /usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file /content/a.mp4, 691200 bytes wanted but 0 bytes read,at frame 7189/7190, at time 239.87/239.89 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/output_video.mp4\n"
          ]
        }
      ]
    }
  ]
}